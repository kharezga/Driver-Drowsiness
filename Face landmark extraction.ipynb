{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[15145]: Class CaptureDelegate is implemented in both /Users/M374155/miniforge3/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x15d7765a0) and /Users/M374155/miniforge3/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x15e7f8860). One of the two will be used. Which one is undefined.\n",
      "objc[15145]: Class CVWindow is implemented in both /Users/M374155/miniforge3/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x15d7765f0) and /Users/M374155/miniforge3/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x12c80ca68). One of the two will be used. Which one is undefined.\n",
      "objc[15145]: Class CVView is implemented in both /Users/M374155/miniforge3/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x15d776618) and /Users/M374155/miniforge3/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x12c80ca90). One of the two will be used. Which one is undefined.\n",
      "objc[15145]: Class CVSlider is implemented in both /Users/M374155/miniforge3/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x15d776640) and /Users/M374155/miniforge3/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x12c80cab8). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "from os.path import exists\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy files from orginal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set the path of the parent directory\n",
    "parent_directory = \"/Users/M374155/Desktop/Preprared New Dataset\"\n",
    "\n",
    "# Create a new directory to copy the files to\n",
    "new_directory = \"/Users/M374155/Desktop/Test/NonSleepy\"\n",
    "\n",
    "# Create the new directory if it doesn't already exist\n",
    "if not os.path.exists(new_directory):\n",
    "    os.makedirs(new_directory)\n",
    "\n",
    "# Counter for the new directory names\n",
    "counter = 1\n",
    "for partent_dir_numer in range (1, 20):\n",
    "    directory = os.path.join(parent_directory, str(partent_dir_numer))\n",
    "    # Loop through each subdirectory of the parent directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file is called \"sleepyCombination.avi\"\n",
    "            if file == \"nonsleepyCombination.avi\":\n",
    "                # Create the new subdirectory for this file\n",
    "                new_subdirectory = os.path.join(new_directory, str(counter))\n",
    "                os.makedirs(new_subdirectory, exist_ok=True)\n",
    "                # Copy the file to the new subdirectory\n",
    "                shutil.copy2(os.path.join(root, file), os.path.join(new_subdirectory, file))\n",
    "                # Increment the counter\n",
    "                counter += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create folders for extracted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('Extracted_Values_Bigger_Confidence/')\n",
    "\n",
    "for state in [\"Sleepy\", \"NonSleepy\"]:\n",
    "    for number in range(1,90):\n",
    "            try:\n",
    "                os.makedirs(os.path.join(DATA_PATH, state , str(number)))\n",
    "            except:\n",
    "                pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to solve openCV problem use version 4.5.5.62"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract face features from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractKeypoints(result):\n",
    "    if result.multi_face_landmarks:\n",
    "        for face_detected in result.multi_face_landmarks:\n",
    "            face = np.array([[res.x, res.y, res.z] for res in face_detected.landmark]).flatten()\n",
    "    else:\n",
    "        face = np.zeros(1434)\n",
    "\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLandmarks(mp_face_mesh, results, frame): \n",
    "    mp_drawing = mp.solutions.drawing_utils  \n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(image=frame, landmark_list=face_landmarks, connections=mp_face_mesh.FACEMESH_TESSELATION, landmark_drawing_spec=None, connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "            mp_drawing.draw_landmarks(image=frame, landmark_list=face_landmarks, connections=mp_face_mesh.FACEMESH_CONTOURS, landmark_drawing_spec=None, connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "            mp_drawing.draw_landmarks(image=frame, landmark_list=face_landmarks, connections=mp_face_mesh.FACEMESH_IRISES, landmark_drawing_spec=None, connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2803\n",
      "3330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NULL @ 0x2a9bbc110] time_scale/num_units_in_tick invalid or unsupported (0/0)\n",
      "[NULL @ 0x2a9bbc110] Overread VUI by 8 bits\n",
      "[h264 @ 0x299182370] corrupted macroblock 34 4 (total_coeff=-1)\n",
      "[h264 @ 0x299182370] error while decoding MB 34 4\n",
      "[h264 @ 0x299182370] Invalid level prefix\n",
      "[h264 @ 0x299182370] error while decoding MB 23 25\n",
      "[h264 @ 0x29918b780] illegal short term buffer state detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1513\n",
      "2732\n",
      "1497\n",
      "2880\n",
      "2934\n",
      "1260\n",
      "2679\n",
      "3086\n",
      "3073\n",
      "1445\n",
      "3302\n",
      "1428\n",
      "2959\n",
      "2868\n",
      "1405\n",
      "2888\n",
      "1426\n",
      "2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NULL @ 0x2967e7f00] time_scale/num_units_in_tick invalid or unsupported (0/0)\n",
      "[NULL @ 0x2967e7f00] Overread VUI by 8 bits\n",
      "[h264 @ 0x17f89d040] Invalid level prefix\n",
      "[h264 @ 0x17f89d040] error while decoding MB 26 6\n",
      "[h264 @ 0x17f89d040] out of range intra chroma pred mode\n",
      "[h264 @ 0x17f89d040] error while decoding MB 31 23\n",
      "[h264 @ 0x17f8e0c80] illegal short term buffer state detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2905\n",
      "1410\n",
      "2861\n",
      "1431\n",
      "2941\n",
      "2856\n",
      "1442\n",
      "2868\n",
      "1964\n",
      "3019\n",
      "2940\n",
      "1754\n",
      "2879\n",
      "1538\n",
      "2950\n",
      "3231\n",
      "1581\n",
      "3080\n",
      "1435\n",
      "3234\n",
      "3029\n",
      "1434\n",
      "2926\n",
      "1382\n",
      "2923\n",
      "3115\n",
      "1412\n",
      "2930\n",
      "2228\n",
      "2816\n",
      "2927\n",
      "1611\n",
      "2847\n",
      "1548\n",
      "2909\n",
      "4060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NULL @ 0x2a9be7eb0] missing picture in access unit with size 16\n",
      "[h264 @ 0x29ff2b8c0] No start code is found.\n",
      "[h264 @ 0x29ff2b8c0] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9be7eb0] missing picture in access unit with size 16\n",
      "[h264 @ 0x29fffda20] No start code is found.\n",
      "[h264 @ 0x29fffda20] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9be7eb0] missing picture in access unit with size 16\n",
      "[h264 @ 0x29ffcd080] No start code is found.\n",
      "[h264 @ 0x29ffcd080] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9be7eb0] missing picture in access unit with size 16\n",
      "[h264 @ 0x29e2cd1b0] No start code is found.\n",
      "[h264 @ 0x29e2cd1b0] Error splitting the input into NAL units.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594\n",
      "3462\n",
      "1436\n",
      "2997\n",
      "3030\n",
      "1456\n",
      "3033\n",
      "1494\n",
      "2944\n",
      "3076\n",
      "1446\n",
      "3114\n",
      "1449\n",
      "4294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x17f893af0] decode_slice_header error\n",
      "[h264 @ 0x17f893af0] decode_slice_header error\n",
      "[h264 @ 0x17f893af0] decode_slice_header error\n",
      "[h264 @ 0x17f893af0] decode_slice_header error\n",
      "[h264 @ 0x17f893af0] decode_slice_header error\n",
      "[NULL @ 0x2a9b8e7d0] missing picture in access unit with size 16\n",
      "[h264 @ 0x17f893af0] No start code is found.\n",
      "[h264 @ 0x17f893af0] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9b8e7d0] missing picture in access unit with size 16\n",
      "[h264 @ 0x17f8ccd40] No start code is found.\n",
      "[h264 @ 0x17f8ccd40] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9b8e7d0] missing picture in access unit with size 16\n",
      "[h264 @ 0x17f8ce4c0] No start code is found.\n",
      "[h264 @ 0x17f8ce4c0] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9b8e7d0] missing picture in access unit with size 16\n",
      "[h264 @ 0x17f88b390] No start code is found.\n",
      "[h264 @ 0x17f88b390] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9b8e7d0] missing picture in access unit with size 16\n",
      "[h264 @ 0x17f8a7e20] No start code is found.\n",
      "[h264 @ 0x17f8a7e20] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9b8e7d0] missing picture in access unit with size 16\n",
      "[h264 @ 0x17fc290d0] No start code is found.\n",
      "[h264 @ 0x17fc290d0] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9b8e7d0] missing picture in access unit with size 16\n",
      "[h264 @ 0x17f8afdc0] No start code is found.\n",
      "[h264 @ 0x17f8afdc0] Error splitting the input into NAL units.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2923\n",
      "1444\n",
      "2828\n",
      "1569\n",
      "3010\n",
      "2906\n",
      "1475\n",
      "2911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NULL @ 0x11f9d50c0] time_scale/num_units_in_tick invalid or unsupported (0/0)\n",
      "[NULL @ 0x11f9d50c0] Overread VUI by 8 bits\n",
      "[h264 @ 0x29ff0dc70] Invalid level prefix\n",
      "[h264 @ 0x29ff0dc70] error while decoding MB 29 4\n",
      "[h264 @ 0x29ff0dc70] corrupted macroblock 28 25 (total_coeff=-1)\n",
      "[h264 @ 0x29ff0dc70] error while decoding MB 28 25\n",
      "[h264 @ 0x29ff30110] illegal short term buffer state detected\n",
      "[NULL @ 0x11f9d50c0] time_scale/num_units_in_tick invalid or unsupported (0/0)\n",
      "[h264 @ 0x29fff33b0] corrupted macroblock 29 19 (total_coeff=-1)\n",
      "[h264 @ 0x29fff33b0] error while decoding MB 29 19\n",
      "[h264 @ 0x29fff33b0] corrupted macroblock 27 10 (total_coeff=-1)\n",
      "[h264 @ 0x29fff33b0] error while decoding MB 27 10\n",
      "[h264 @ 0x29ff0dc70] illegal short term buffer state detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1538\n",
      "2882\n",
      "2918\n",
      "1420\n",
      "2861\n",
      "1555\n",
      "4460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NULL @ 0x2a9be19a0] missing picture in access unit with size 16\n",
      "[h264 @ 0x29fffb210] No start code is found.\n",
      "[h264 @ 0x29fffb210] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9be19a0] missing picture in access unit with size 16\n",
      "[h264 @ 0x29fffda20] No start code is found.\n",
      "[h264 @ 0x29fffda20] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9be19a0] missing picture in access unit with size 16\n",
      "[h264 @ 0x29faaab90] No start code is found.\n",
      "[h264 @ 0x29faaab90] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9be19a0] missing picture in access unit with size 16\n",
      "[h264 @ 0x29ffe1220] No start code is found.\n",
      "[h264 @ 0x29ffe1220] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9be19a0] missing picture in access unit with size 16\n",
      "[h264 @ 0x29ff0e7b0] No start code is found.\n",
      "[h264 @ 0x29ff0e7b0] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9be19a0] missing picture in access unit with size 16\n",
      "[h264 @ 0x29ff0abb0] No start code is found.\n",
      "[h264 @ 0x29ff0abb0] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9be19a0] missing picture in access unit with size 16\n",
      "[h264 @ 0x29ffe5ca0] No start code is found.\n",
      "[h264 @ 0x29ffe5ca0] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9be19a0] missing picture in access unit with size 16\n",
      "[h264 @ 0x29fff5390] No start code is found.\n",
      "[h264 @ 0x29fff5390] Error splitting the input into NAL units.\n",
      "[NULL @ 0x2a9be19a0] missing picture in access unit with size 16\n",
      "[h264 @ 0x29e2ef7e0] No start code is found.\n",
      "[h264 @ 0x29e2ef7e0] Error splitting the input into NAL units.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3168\n",
      "1558\n",
      "2946\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils  \n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "folder_numbers = range(1,3)\n",
    "drowsiness_level = np.array(['NonSleepy', 'Sleepy'])\n",
    "\n",
    "for state in [\"Sleepy\", \"NonSleepy\"]:\n",
    "    for number in folder_numbers:\n",
    "            videoName = \"sleepyCombination.avi\" if state == \"Sleepy\" else \"nonsleepyCombination.avi\"\n",
    "            videoPath = os.path.join('/Users/M374155/Desktop/Test/', state, str(number), videoName)\n",
    "            cap = cv.VideoCapture(videoPath)\n",
    "            frame_count = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "            print(frame_count)\n",
    "            with mp_face_mesh.FaceMesh(\n",
    "                refine_landmarks=True,\n",
    "                min_detection_confidence=0.6,\n",
    "                min_tracking_confidence = 0.8) as mesh:\n",
    "\n",
    "                for frame_number in range(frame_count):\n",
    "                    ret, frame = cap.read()\n",
    "                \n",
    "                    image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)  \n",
    "                    image.flags.writeable = False \n",
    "                    results = mesh.process(image)\n",
    "                    image.flags.writeable = True\n",
    "                    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)  \n",
    "\n",
    "                    drawLandmarks(mp_face_mesh=mp_face_mesh, results=results, frame=image)\n",
    "\n",
    "                    landmarks = extractKeypoints(results)\n",
    "                    npyPath = os.path.join(\"./Extracted_Values/Sleepy\", str(number), str(frame_number))\n",
    "                    # np.save(npyPath, landmarks)\n",
    "\n",
    "                    cv.imshow('Video', image)\n",
    "                    if cv.waitKey(1) == ord('q'):\n",
    "                        break\n",
    "            cap.release()\n",
    "            cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7af61bf7e85a63f645af3a4c590de47c9dba01176dacef0e93b7460b494eae3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
