{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[25768]: Class CaptureDelegate is implemented in both /Users/M374155/miniforge3/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x16b7765a0) and /Users/M374155/miniforge3/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x137a1c860). One of the two will be used. Which one is undefined.\n",
      "objc[25768]: Class CVWindow is implemented in both /Users/M374155/miniforge3/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x16b7765f0) and /Users/M374155/miniforge3/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x127384a68). One of the two will be used. Which one is undefined.\n",
      "objc[25768]: Class CVView is implemented in both /Users/M374155/miniforge3/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x16b776618) and /Users/M374155/miniforge3/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x127384a90). One of the two will be used. Which one is undefined.\n",
      "objc[25768]: Class CVSlider is implemented in both /Users/M374155/miniforge3/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x16b776640) and /Users/M374155/miniforge3/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x127384ab8). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "from os.path import exists\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractKeypoints(result):\n",
    "    if result.multi_face_landmarks:\n",
    "        for face_detected in result.multi_face_landmarks:\n",
    "            face = np.array([[res.x, res.y, res.z] for res in face_detected.landmark]).flatten()\n",
    "    else:\n",
    "        face = np.zeros(1434)\n",
    "\n",
    "    return face\n",
    "\n",
    "def drawLandmarks(mp_face_mesh, results, frame): \n",
    "    mp_drawing = mp.solutions.drawing_utils  \n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(image=frame, landmark_list=face_landmarks,\n",
    "                                       connections=mp_face_mesh.FACEMESH_TESSELATION, \n",
    "                                       landmark_drawing_spec=None,\n",
    "                                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "            mp_drawing.draw_landmarks(image=frame, landmark_list=face_landmarks,\n",
    "                                       connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                                         landmark_drawing_spec=None,\n",
    "                                           connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "            mp_drawing.draw_landmarks(image=frame, landmark_list=face_landmarks,\n",
    "                                       connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                                         landmark_drawing_spec=None,\n",
    "                                           connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())\n",
    "            \n",
    "def revertColors(frame, mesh): \n",
    "    image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)  \n",
    "    image.flags.writeable = False \n",
    "    results = mesh.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)  \n",
    "    \n",
    "    return image, results "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Nodding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('./Nodding_Extracted_Values//')\n",
    "\n",
    "for state in [\"Nodding\", \"NonNodding\"]:\n",
    "    for number in range(1,91):\n",
    "            videoIndex  = str(number).zfill(3)\n",
    "            try:\n",
    "                os.makedirs(os.path.join(DATA_PATH, state , str(videoIndex)))\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video number:  1  for state  glasses  Save Index:   1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video number:  1  for state  noglasses  Save Index:   2\n",
      "Processing video number:  1  for state  night_noglasses  Save Index:   3\n",
      "Processing video number:  1  for state  sunglasses  Save Index:   4\n",
      "Processing video number:  1  for state  nightglasses  Save Index:   5\n",
      "Processing video number:  36  for state  glasses  Save Index:   6\n",
      "Processing video number:  36  for state  noglasses  Save Index:   7\n",
      "Processing video number:  36  for state  night_noglasses  Save Index:   8\n",
      "Processing video number:  36  for state  sunglasses  Save Index:   9\n",
      "Processing video number:  36  for state  nightglasses  Save Index:   10\n",
      "Processing video number:  2  for state  glasses  Save Index:   11\n",
      "Processing video number:  2  for state  noglasses  Save Index:   12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NULL @ 0x2ccad8ae0] time_scale/num_units_in_tick invalid or unsupported (0/0)\n",
      "[NULL @ 0x2ccad8ae0] Overread VUI by 8 bits\n",
      "[h264 @ 0x2cd623610] Invalid level prefix\n",
      "[h264 @ 0x2cd623610] error while decoding MB 5 4\n",
      "[h264 @ 0x2cd623610] cbp too large (3199971767) at 36 25\n",
      "[h264 @ 0x2cd623610] error while decoding MB 36 25\n",
      "[h264 @ 0x2cd61ed60] illegal short term buffer state detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video number:  2  for state  night_noglasses  Save Index:   13\n",
      "Processing video number:  2  for state  sunglasses  Save Index:   14\n",
      "Processing video number:  2  for state  nightglasses  Save Index:   15\n",
      "Processing video number:  6  for state  glasses  Save Index:   16\n",
      "Processing video number:  6  for state  noglasses  Save Index:   17\n",
      "Processing video number:  6  for state  night_noglasses  Save Index:   18\n",
      "Processing video number:  6  for state  sunglasses  Save Index:   19\n",
      "Processing video number:  6  for state  nightglasses  Save Index:   20\n",
      "Processing video number:  8  for state  glasses  Save Index:   21\n",
      "Processing video number:  8  for state  noglasses  Save Index:   22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NULL @ 0x2cde5ec80] time_scale/num_units_in_tick invalid or unsupported (0/0)\n",
      "[NULL @ 0x2cde5ec80] Overread VUI by 8 bits\n",
      "[h264 @ 0x2cdef97f0] corrupted macroblock 24 4 (total_coeff=-1)\n",
      "[h264 @ 0x2cdef97f0] error while decoding MB 24 4\n",
      "[h264 @ 0x2cdef97f0] corrupted macroblock 6 26 (total_coeff=-1)\n",
      "[h264 @ 0x2cdef97f0] error while decoding MB 6 26\n",
      "[h264 @ 0x2cdef83a0] illegal short term buffer state detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video number:  8  for state  night_noglasses  Save Index:   23\n",
      "Processing video number:  8  for state  sunglasses  Save Index:   24\n",
      "Processing video number:  8  for state  nightglasses  Save Index:   25\n",
      "Processing video number:  9  for state  glasses  Save Index:   26\n",
      "Processing video number:  9  for state  noglasses  Save Index:   27\n",
      "Processing video number:  9  for state  night_noglasses  Save Index:   28\n",
      "Processing video number:  9  for state  sunglasses  Save Index:   29\n",
      "Processing video number:  9  for state  nightglasses  Save Index:   30\n",
      "Processing video number:  12  for state  glasses  Save Index:   31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NULL @ 0x2cd9a2ab0] time_scale/num_units_in_tick invalid or unsupported (0/0)\n",
      "[NULL @ 0x2cd9a2ab0] Overread VUI by 8 bits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video number:  12  for state  noglasses  Save Index:   32\n",
      "Processing video number:  12  for state  night_noglasses  Save Index:   33\n",
      "Processing video number:  12  for state  sunglasses  Save Index:   34\n",
      "Processing video number:  12  for state  nightglasses  Save Index:   35\n",
      "Processing video number:  13  for state  glasses  Save Index:   36\n",
      "Processing video number:  13  for state  noglasses  Save Index:   37\n",
      "Processing video number:  13  for state  night_noglasses  Save Index:   38\n",
      "Processing video number:  13  for state  sunglasses  Save Index:   39\n",
      "Processing video number:  13  for state  nightglasses  Save Index:   40\n",
      "Processing video number:  15  for state  glasses  Save Index:   41\n",
      "Processing video number:  15  for state  noglasses  Save Index:   42\n",
      "Processing video number:  15  for state  night_noglasses  Save Index:   43\n",
      "Processing video number:  15  for state  sunglasses  Save Index:   44\n",
      "Processing video number:  15  for state  nightglasses  Save Index:   45\n",
      "Processing video number:  20  for state  glasses  Save Index:   46\n",
      "Processing video number:  20  for state  noglasses  Save Index:   47\n",
      "Processing video number:  20  for state  night_noglasses  Save Index:   48\n",
      "Processing video number:  20  for state  sunglasses  Save Index:   49\n",
      "Processing video number:  20  for state  nightglasses  Save Index:   50\n",
      "Processing video number:  23  for state  glasses  Save Index:   51\n",
      "Processing video number:  23  for state  noglasses  Save Index:   52\n",
      "Processing video number:  23  for state  night_noglasses  Save Index:   53\n",
      "Processing video number:  23  for state  sunglasses  Save Index:   54\n",
      "Processing video number:  23  for state  nightglasses  Save Index:   55\n",
      "Processing video number:  24  for state  glasses  Save Index:   56\n",
      "Processing video number:  24  for state  noglasses  Save Index:   57\n",
      "Processing video number:  24  for state  night_noglasses  Save Index:   58\n",
      "Processing video number:  24  for state  sunglasses  Save Index:   59\n",
      "Processing video number:  24  for state  nightglasses  Save Index:   60\n",
      "Processing video number:  31  for state  glasses  Save Index:   61\n",
      "Processing video number:  31  for state  noglasses  Save Index:   62\n",
      "Processing video number:  31  for state  night_noglasses  Save Index:   63\n",
      "Processing video number:  31  for state  sunglasses  Save Index:   64\n",
      "Processing video number:  31  for state  nightglasses  Save Index:   65\n",
      "Processing video number:  32  for state  glasses  Save Index:   66\n",
      "Processing video number:  32  for state  noglasses  Save Index:   67\n",
      "Processing video number:  32  for state  night_noglasses  Save Index:   68\n",
      "Processing video number:  32  for state  sunglasses  Save Index:   69\n",
      "Processing video number:  32  for state  nightglasses  Save Index:   70\n",
      "Processing video number:  33  for state  glasses  Save Index:   71\n",
      "Processing video number:  33  for state  noglasses  Save Index:   72\n",
      "Processing video number:  33  for state  night_noglasses  Save Index:   73\n",
      "Processing video number:  33  for state  sunglasses  Save Index:   74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NULL @ 0x2cf945650] time_scale/num_units_in_tick invalid or unsupported (0/0)\n",
      "[NULL @ 0x2cf945650] Overread VUI by 8 bits\n",
      "[h264 @ 0x2cf9c1bf0] Invalid level prefix\n",
      "[h264 @ 0x2cf9c1bf0] error while decoding MB 23 4\n",
      "[h264 @ 0x2cf9c1bf0] Invalid level prefix\n",
      "[h264 @ 0x2cf9c1bf0] error while decoding MB 7 26\n",
      "[h264 @ 0x2cf9cb000] illegal short term buffer state detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video number:  33  for state  nightglasses  Save Index:   75\n",
      "Processing video number:  34  for state  glasses  Save Index:   76\n",
      "Processing video number:  34  for state  noglasses  Save Index:   77\n",
      "Processing video number:  34  for state  night_noglasses  Save Index:   78\n",
      "Processing video number:  34  for state  sunglasses  Save Index:   79\n",
      "Processing video number:  34  for state  nightglasses  Save Index:   80\n",
      "Processing video number:  35  for state  glasses  Save Index:   81\n",
      "Processing video number:  35  for state  noglasses  Save Index:   82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NULL @ 0x2cf630300] time_scale/num_units_in_tick invalid or unsupported (0/0)\n",
      "[NULL @ 0x2cf630300] Overread VUI by 8 bits\n",
      "[h264 @ 0x2cf67d270] Invalid level prefix\n",
      "[h264 @ 0x2cf67d270] error while decoding MB 29 4\n",
      "[h264 @ 0x2cf67d270] Invalid level prefix\n",
      "[h264 @ 0x2cf67d270] error while decoding MB 15 26\n",
      "[h264 @ 0x2cf686680] illegal short term buffer state detected\n",
      "[NULL @ 0x2cf630300] time_scale/num_units_in_tick invalid or unsupported (0/0)\n",
      "[h264 @ 0x2cf6ab6c0] negative number of zero coeffs at 39 8\n",
      "[h264 @ 0x2cf6ab6c0] error while decoding MB 39 8\n",
      "[h264 @ 0x2cf6ab6c0] Invalid level prefix\n",
      "[h264 @ 0x2cf6ab6c0] error while decoding MB 31 23\n",
      "[h264 @ 0x2cf668f00] illegal short term buffer state detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video number:  35  for state  night_noglasses  Save Index:   83\n",
      "Processing video number:  35  for state  sunglasses  Save Index:   84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NULL @ 0x2cf4a6130] time_scale/num_units_in_tick invalid or unsupported (0/0)\n",
      "[NULL @ 0x2cf4a6130] Overread VUI by 8 bits\n",
      "[h264 @ 0x2cf4c96d0] Invalid level prefix\n",
      "[h264 @ 0x2cf4c96d0] error while decoding MB 0 10\n",
      "[h264 @ 0x2cf4c96d0] Invalid level prefix\n",
      "[h264 @ 0x2cf4c96d0] error while decoding MB 15 21\n",
      "[h264 @ 0x2cf4b9a40] illegal short term buffer state detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video number:  35  for state  nightglasses  Save Index:   85\n",
      "Processing video number:  5  for state  glasses  Save Index:   86\n",
      "Processing video number:  5  for state  noglasses  Save Index:   87\n",
      "Processing video number:  5  for state  night_noglasses  Save Index:   88\n",
      "Processing video number:  5  for state  sunglasses  Save Index:   89\n",
      "Processing video number:  5  for state  nightglasses  Save Index:   90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/Users/M374155/Desktop/New Dataset/Training_Evaluation_Dataset/Training Dataset/005/nightglasses/slowBlinkWithNodding.avi\"\n",
      "[ERROR:0@7095.287] global cap.cpp:166 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): /Users/M374155/Desktop/New Dataset/Training_Evaluation_Dataset/Training Dataset/005/nightglasses/slowBlinkWithNodding.avi in function 'icvExtractPattern'\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/M374155/Desktop/New Dataset/Training_Evaluation_Dataset/Training Dataset/005/nightglasses/005_slowBlinkWithNodding_head.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m textFilePath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m/Users/M374155/Desktop/New Dataset/Training_Evaluation_Dataset/Training Dataset/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m     16\u001b[0m                             videoIndex \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m state \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m videoIndex \u001b[39m+\u001b[39m textFileName)\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mProcessing video number: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(videoNumber), \u001b[39m\"\u001b[39m\u001b[39m for state \u001b[39m\u001b[39m\"\u001b[39m, state, \u001b[39m\"\u001b[39m\u001b[39m Save Index:  \u001b[39m\u001b[39m\"\u001b[39m, saveVideoIndex)\n\u001b[0;32m---> 19\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(textFilePath, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m     20\u001b[0m     noddingFrameCounter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     21\u001b[0m     nonNoddingFrameCounter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/M374155/Desktop/New Dataset/Training_Evaluation_Dataset/Training Dataset/005/nightglasses/005_slowBlinkWithNodding_head.txt'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils  \n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "videoNumberRange = [1, 36, 2, 6, 8, 9, 12, 13, 15, 20, 23, 24, 31, 32, 33, 34, 35, 5]\n",
    "\n",
    "saveVideoIndex = 1\n",
    "for videoNumber in videoNumberRange:\n",
    "    for state in [\"glasses\", \"noglasses\", \"night_noglasses\", \"sunglasses\", \"nightglasses\"]:\n",
    "        videoIndex = str(videoNumber).zfill(3)\n",
    "        videoPath = os.path.join('/Users/M374155/Desktop/New Dataset/Training_Evaluation_Dataset/Training Dataset/' +\n",
    "                                 videoIndex + \"/\" + state + \"/slowBlinkWithNodding.avi\")\n",
    "        cap = cv.VideoCapture(videoPath)\n",
    "        textFileName = \"_slowBlinkWithNodding_head.txt\"\n",
    "        textFilePath = os.path.join('/Users/M374155/Desktop/New Dataset/Training_Evaluation_Dataset/Training Dataset/' +\n",
    "                                    videoIndex + \"/\" + state + \"/\" + videoIndex + textFileName)\n",
    "        print(\"Processing video number: \", str(videoNumber), \" for state \", state, \" Save Index:  \", saveVideoIndex)\n",
    "\n",
    "        with open(textFilePath, 'r') as file:\n",
    "            noddingFrameCounter = 0\n",
    "            nonNoddingFrameCounter = 0\n",
    "            for char in file.read():\n",
    "                if char == \"1\":\n",
    "                    savePath = os.path.join(\"./Nodding_Extracted_Values/Nodding/\", str(saveVideoIndex).zfill(3), str(noddingFrameCounter))\n",
    "                    noddingFrameCounter += 1\n",
    "                else:\n",
    "                    savePath = os.path.join(\"./Nodding_Extracted_Values/NonNodding/\", str(saveVideoIndex).zfill(3), str(nonNoddingFrameCounter))\n",
    "                    nonNoddingFrameCounter += 1\n",
    "\n",
    "                with mp_face_mesh.FaceMesh(\n",
    "                                refine_landmarks=True,\n",
    "                                min_detection_confidence=0.6,\n",
    "                                min_tracking_confidence=0.7) as mesh:\n",
    "                    \n",
    "                    ret, frame = cap.read()               \n",
    "                    image, results = revertColors(frame, mesh)\n",
    "                    drawLandmarks(mp_face_mesh, results, image)\n",
    "                    landmarks = extractKeypoints(results)\n",
    "\n",
    "                    np.save(savePath, landmarks)\n",
    "                    cv.imshow('Video', image)\n",
    "                                    \n",
    "                    if cv.waitKey(1) == ord('q'):\n",
    "                        break              \n",
    "\n",
    "        cap.release()\n",
    "        saveVideoIndex += 1\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Yawning values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('./Yawning//')\n",
    "\n",
    "for state in [\"Yawning\", \"NonYawning\"]:\n",
    "    for number in range(1,91):\n",
    "            videoIndex  = str(number).zfill(3)\n",
    "            try:\n",
    "                os.makedirs(os.path.join(DATA_PATH, state , str(videoIndex)))\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils  \n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "videoNumberRange = [1, 36, 2, 6, 8, 9, 12, 13, 15, 20, 23, 24, 31, 32, 33, 34, 35, 5]\n",
    "\n",
    "saveVideoIndex = 1\n",
    "for videoNumber in videoNumberRange:\n",
    "    for state in [\"glasses\", \"noglasses\", \"night_noglasses\", \"sunglasses\", \"nightglasses\"]:\n",
    "        videoIndex = str(videoNumber).zfill(3)\n",
    "        videoPath = os.path.join('/Users/M374155/Desktop/New Dataset/Training_Evaluation_Dataset/Training Dataset/' +\n",
    "                                 videoIndex + \"/\" + state + \"/yawning.avi\")\n",
    "        cap = cv.VideoCapture(videoPath)\n",
    "        textFileName = \"_yawning_mouth.txt\"\n",
    "        textFilePath = os.path.join('/Users/M374155/Desktop/New Dataset/Training_Evaluation_Dataset/Training Dataset/' +\n",
    "                                    videoIndex + \"/\" + state + \"/\" + videoIndex + textFileName)\n",
    "        print(\"Processing video number: \", str(videoNumber), \" for state \", state, \" Save Index:  \", saveVideoIndex)\n",
    "\n",
    "        with open(textFilePath, 'r') as file:\n",
    "            yawningFrameCounter = 0\n",
    "            nonYawningFrameCounter = 0\n",
    "            for char in file.read():\n",
    "                if char == \"1\":\n",
    "                    savePath = os.path.join(\"./Yawning/Yawning/\", str(saveVideoIndex).zfill(3), str(yawningFrameCounter))\n",
    "                    yawningFrameCounter += 1\n",
    "                else:\n",
    "                    savePath = os.path.join(\"./Yawning/NonYawning/\", str(saveVideoIndex).zfill(3), str(nonYawningFrameCounter))\n",
    "                    nonYawningFrameCounter += 1\n",
    "\n",
    "                with mp_face_mesh.FaceMesh(\n",
    "                                refine_landmarks=True,\n",
    "                                min_detection_confidence=0.6,\n",
    "                                min_tracking_confidence=0.7) as mesh:\n",
    "                    \n",
    "                    ret, frame = cap.read()               \n",
    "                    image, results = revertColors(frame, mesh)\n",
    "                    drawLandmarks(mp_face_mesh, results, image)\n",
    "                    landmarks = extractKeypoints(results)\n",
    "\n",
    "                    np.save(savePath, landmarks)\n",
    "                    cv.imshow('Video', image)\n",
    "                                    \n",
    "                    if cv.waitKey(1) == ord('q'):\n",
    "                        break              \n",
    "\n",
    "        cap.release()\n",
    "        saveVideoIndex += 1\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Eyes values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('./Eyes_Extracted_Values//')\n",
    "\n",
    "for state in [\"Sleepy\", \"NonSleepy\"]:\n",
    "    for number in range(1,91):\n",
    "            videoIndex  = str(number).zfill(3)\n",
    "            try:\n",
    "                os.makedirs(os.path.join(DATA_PATH, state , str(videoIndex)))\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils  \n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "videoNumberRange = [1, 36, 2, 6, 8, 9, 12, 13, 15, 20, 23, 24, 31, 32, 33, 34, 35, 5]\n",
    "\n",
    "saveVideoIndex = 1\n",
    "for videoNumber in videoNumberRange:\n",
    "    for state in [\"glasses\", \"noglasses\", \"night_noglasses\", \"sunglasses\", \"nightglasses\"]:\n",
    "        videoIndex = str(videoNumber).zfill(3)\n",
    "        videoPath = os.path.join('/Users/M374155/Desktop/New Dataset/Training_Evaluation_Dataset/Training Dataset/' +\n",
    "                                 videoIndex + \"/\" + state + \"/slowBlinkWithNodding.avi\")\n",
    "        cap = cv.VideoCapture(videoPath)\n",
    "        textFileName = \"_slowBlinkWithNodding_eye.txt\"\n",
    "        textFilePath = os.path.join('/Users/M374155/Desktop/New Dataset/Training_Evaluation_Dataset/Training Dataset/' +\n",
    "                                    videoIndex + \"/\" + state + \"/\" + videoIndex + textFileName)\n",
    "        print(\"Processing video number: \", str(videoNumber), \" for state \", state, \" Save Index:  \", saveVideoIndex)\n",
    "\n",
    "        with open(textFilePath, 'r') as file:\n",
    "            sleepyEyesFrameCounter = 0\n",
    "            nonSleepyEyesFrameCounter = 0\n",
    "            for char in file.read():\n",
    "                if char == \"1\":\n",
    "                    savePath = os.path.join(\"./Eyes_Extracted_Values/Sleepy/\", str(saveVideoIndex).zfill(3), str(sleepyEyesFrameCounter))\n",
    "                    sleepyEyesFrameCounter += 1\n",
    "                else:\n",
    "                    savePath = os.path.join(\"./Eyes_Extracted_Values/NonSleepy/\", str(saveVideoIndex).zfill(3), str(nonSleepyEyesFrameCounter))\n",
    "                    nonSleepyEyesFrameCounter += 1\n",
    "\n",
    "                with mp_face_mesh.FaceMesh(\n",
    "                                refine_landmarks=True,\n",
    "                                min_detection_confidence=0.6,\n",
    "                                min_tracking_confidence=0.7) as mesh:\n",
    "                    \n",
    "                    ret, frame = cap.read()               \n",
    "                    image, results = revertColors(frame, mesh)\n",
    "                    drawLandmarks(mp_face_mesh, results, image)\n",
    "                    landmarks = extractKeypoints(results)\n",
    "\n",
    "                    np.save(savePath, landmarks)\n",
    "                    cv.imshow('Video', image)\n",
    "                                    \n",
    "                    if cv.waitKey(1) == ord('q'):\n",
    "                        break              \n",
    "\n",
    "        cap.release()\n",
    "        saveVideoIndex += 1\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
